{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from joblib import dump, load\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = ['not_crossing_wen', 'not_crossing_nick', 'not_crossing']\n",
    "locations_crossing = ['crossing_wen', 'crossing_nick', 'crossing']\n",
    "\n",
    "not_crossing = defaultdict(list)\n",
    "crossing = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read only the valid data into dict\n",
    "\n",
    "for location in locations:\n",
    "    path = 'data/' + location + '/'\n",
    "    for filename in glob.glob(path + '*.csv'):\n",
    "        name = filename.replace(path, '')[:-4]\n",
    "\n",
    "        df=pd.read_csv(filename)\n",
    "        if len(df.columns) >= 5 * 2: # 2 columns per point for x & y\n",
    "            for data in df.values:\n",
    "                not_crossing[name].append(data)\n",
    "                \n",
    "for location in locations_crossing:\n",
    "    path = 'data/' + location + '/'\n",
    "    for filename in glob.glob(path + '*.csv'):\n",
    "        name = filename.replace(path, '')[:-4]\n",
    "\n",
    "        df=pd.read_csv(filename)\n",
    "        if len(df.columns) >= 5 * 2: # 2 columns per point for x & y\n",
    "            for data in df.values:\n",
    "                crossing[name].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "crossing['01234567891011121314151617'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "\n",
    "def extract(datum, label):\n",
    "#     print(datum)\n",
    "    return (label, [float(d) for d in datum])\n",
    "\n",
    "model_scores = []\n",
    "\n",
    "for filename in glob.glob('models/*.sav'):\n",
    "    os.remove(filename)\n",
    "\n",
    "for key in not_crossing:\n",
    "    if key in crossing:\n",
    "        data = [extract(d, 2) for d in not_crossing[key]]\n",
    "        data += [extract(d, 1) for d in crossing[key]]\n",
    "        \n",
    "        random.shuffle(data)\n",
    "        \n",
    "        X = [d[1] for d in data]\n",
    "        y = [d[0] for d in data]\n",
    "        \n",
    "        N = len(X)\n",
    "        \n",
    "        if N < 8:\n",
    "            continue\n",
    "        \n",
    "        X_train = X[:3*N//4]\n",
    "        X_test = X[3*N//4:]\n",
    "        y_train = y[:3*N//4]\n",
    "        y_test = y[3*N//4:]\n",
    "        \n",
    "#         print(y_train)\n",
    "#         break;\n",
    "        \n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "        \n",
    "        try:\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            \n",
    "            if score < 0.6:\n",
    "                print(\"⚠️ low score \" + key + ' count: ' + str(N), 'score: ' + str(score))\n",
    "            else:\n",
    "                print('✔️ ' + key + ' score: ' + str(score), 'count: ' + str(N))\n",
    "#                 pickle.dump(clf, open('models/' + key + '_{:.2f}'.format(score) + '.sav', 'wb'))\n",
    "                dump(clf, 'models/' + key + '_{:.2f}'.format(score) + '.joblib')\n",
    "            model_scores.append((key, score, N))\n",
    "        except:\n",
    "            # This means there is only one classification in training data. Caused by train/test split\n",
    "            print(\"❌ omitted \" + key + ' count: ' + str(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model_scores, key=lambda tup: (tup[1], tup[2]), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best model: 01234567891011121314151617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for filename in glob.glob('models/*.joblib'):\n",
    "    name = filename.replace('models/', '')[:-12]\n",
    "    print(name)\n",
    "\n",
    "    model_dict[name] = load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [extract(d, 1) for d in not_crossing[\"01234567891011121314151617\"]]\n",
    "data += [extract(d, 2) for d in crossing[\"01234567891011121314151617\"]]\n",
    "\n",
    "# print([extract(d, 1) for d in not_crossing[\"01234567891011121314151617\"]])\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "X = [d[1] for d in data]\n",
    "y = [d[0] for d in data]\n",
    "\n",
    "N = len(X)\n",
    "\n",
    "X_train = X[:3*N//4]\n",
    "X_test = X[3*N//4:]\n",
    "y_train = y[:3*N//4]\n",
    "y_test = y[3*N//4:]\n",
    "\n",
    "# print(model_dict[\"01234567891011121314151617\"].score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"0124567891011121314151617\"\n",
    "\n",
    "cross_arr = np.asarray(crossing[file])\n",
    "cross_arr = [np.append(d, 0) for d in cross_arr]\n",
    "\n",
    "not_cross_arr = np.asarray(not_crossing[file])\n",
    "not_cross_arr = [np.append(d, 1) for d in not_cross_arr]\n",
    "\n",
    "combined_arr = cross_arr + not_cross_arr\n",
    "\n",
    "random.shuffle(combined_arr)\n",
    "\n",
    "N = len(combined_arr)\n",
    "\n",
    "train_arr = combined_arr[:4*N//5]\n",
    "test_arr = combined_arr[4*N//5:]\n",
    "\n",
    "np.savetxt('train.csv', train_arr, delimiter=',')\n",
    "np.savetxt('test.csv', test_arr, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
