{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-pdtv15_t because the default path (/home/jetson/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import pycocotools.coco\n",
    "import pycocotools.cocoeval\n",
    "import os\n",
    "import torch\n",
    "import PIL.Image\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import trt_pose.plugins\n",
    "import trt_pose.models\n",
    "import trt_pose.coco\n",
    "import torch2trt\n",
    "import tqdm\n",
    "import json\n",
    "from trt_pose.parse_objects import ParseObjects\n",
    "import torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-42b611fe5d9a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-42b611fe5d9a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    class My\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@tensorrt_module\n",
    "class My"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trt_pose.models.dla34up_pose(18, 42).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tasks/human_pose/experiments/dla34up_pose_256x256_A.json.checkpoints/epoch_249.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros((1, 3, 256, 256)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch2trt.tensorrt_converter('torch.split')\n",
    "def convert_split_dbg(ctx):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_trt = torch2trt.torch2trt(model.backbone, [data], fp16_mode=True, max_workspace_size=1<<25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_torch = model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone = backbone_trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(torch.abs(model.backbone(data) - backbone_trt(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap, paf = model(torch.zeros((1, 3, 256, 256)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (256, 256)\n",
    "images_dir = 'val2017'\n",
    "annotation_file = 'annotations/person_keypoints_val2017_modified.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoGtTmp = pycocotools.coco.COCO('annotations/person_keypoints_val2017_modified.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = trt_pose.coco.coco_category_to_topology(cocoGtTmp.cats[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoGt = pycocotools.coco.COCO('annotations/person_keypoints_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catIds = cocoGt.getCatIds('person')\n",
    "imgIds = cocoGt.getImgIds(catIds=catIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_objects = ParseObjects(topology, cmap_threshold=0.05, link_threshold=0.1, cmap_window=11, line_integral_samples=7, max_num_parts=100, max_num_objects=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for n, imgId in enumerate(imgIds):\n",
    "    \n",
    "    # read image\n",
    "    img = cocoGt.imgs[imgId]\n",
    "    img_path = os.path.join(images_dir, img['file_name'])\n",
    "\n",
    "    image = PIL.Image.open(img_path).convert('RGB').resize(IMAGE_SHAPE)\n",
    "    data = transform(image).cuda()[None, ...]\n",
    "\n",
    "    cmap, paf = model(data)\n",
    "    cmap, paf = cmap.cpu(), paf.cpu()\n",
    "\n",
    "#     object_counts, objects, peaks, int_peaks = postprocess(cmap, paf, cmap_threshold=0.05, link_threshold=0.01, window=5)\n",
    "#     object_counts, objects, peaks = int(object_counts[0]), objects[0], peaks[0]\n",
    "    \n",
    "    object_counts, objects, peaks = parse_objects(cmap, paf)\n",
    "    object_counts, objects, peaks = int(object_counts[0]), objects[0], peaks[0]\n",
    "\n",
    "    for i in range(object_counts):\n",
    "        object = objects[i]\n",
    "        score = 0.0\n",
    "        kps = [0]*(17*3)\n",
    "        x_mean = 0\n",
    "        y_mean = 0\n",
    "        cnt = 0\n",
    "        for j in range(17):\n",
    "            k = object[j]\n",
    "            if k >= 0:\n",
    "                peak = peaks[j][k]\n",
    "                x = round(float(img['width'] * peak[1]))\n",
    "                y = round(float(img['height'] * peak[0]))\n",
    "                score += 1.0\n",
    "                kps[j * 3 + 0] = x\n",
    "                kps[j * 3 + 1] = y\n",
    "                kps[j * 3 + 2] = 2\n",
    "                x_mean += x\n",
    "                y_mean += y\n",
    "                cnt += 1\n",
    "\n",
    "        ann = {\n",
    "            'image_id': imgId,\n",
    "            'category_id': 1,\n",
    "            'keypoints': kps,\n",
    "            'score': score / 17.0\n",
    "        }\n",
    "        results.append(ann)\n",
    "    if n % 100 == 0:\n",
    "        print('%d / %d' % (n, len(imgIds)))\n",
    "#     break\n",
    "        \n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoDt = cocoGt.loadRes('results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoEval = pycocotools.cocoeval.COCOeval(cocoGt, cocoDt, 'keypoints')\n",
    "cocoEval.params.imgIds = imgIds\n",
    "cocoEval.params.catIds = [1]\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
